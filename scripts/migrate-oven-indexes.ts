import { dbc } from '@/lib/mongo';

/**
 * Migration script to create indexes for oven_processes collection
 * Run with: bun run scripts/migrate-oven-indexes.ts
 */
async function createOvenIndexes() {
  try {
    console.log('ðŸš€ Starting oven_processes index migration...');

    const collection = await dbc('oven_processes');

    // 1. CRITICAL: Unique index to prevent duplicate oven + hydraBatch combinations
    try {
      await collection.createIndex(
        { oven: 1, hydraBatch: 1 },
        {
          unique: true,
          name: 'oven_hydraBatch_unique',
        },
      );
      console.log('âœ… Created unique index: oven_hydraBatch_unique');
    } catch (error: any) {
      if (error.code === 11000) {
        console.log('âš ï¸  Unique index already exists or duplicates found');
        console.log('   Clean up duplicates first, then retry');
      } else {
        console.log(
          'âŒ Failed to create oven_hydraBatch_unique:',
          error.message,
        );
      }
    }

    // 2. Query performance indexes using existing startTime field
    const performanceIndexes = [
      {
        name: 'oven_startTime_desc',
        spec: { oven: 1, startTime: -1 },
        description: 'Optimizes fetchOvenProcesses sorting',
      },
      {
        name: 'oven_status_startTime',
        spec: { oven: 1, status: 1, startTime: -1 },
        description: 'Optimizes filtering by status with sorting',
      },
      {
        name: 'hydraBatch_status',
        spec: { hydraBatch: 1, status: 1 },
        description: 'Optimizes batch lookup and duplicate checking',
      },
      {
        name: 'id_status',
        spec: { _id: 1, status: 1 },
        description: 'Optimizes completeOvenProcess operations',
      },
    ];

    for (const { name, spec, description } of performanceIndexes) {
      try {
        await collection.createIndex(spec as any, { name });
        console.log(`âœ… Created index: ${name} - ${description}`);
      } catch (error: any) {
        console.log(`âŒ Failed to create ${name}:`, error.message);
      }
    }

    // 3. Check results and show all indexes
    console.log('\nðŸ“Š Current indexes on oven_processes collection:');
    const allIndexes = await collection.indexes();
    allIndexes.forEach((index) => {
      const keyStr = JSON.stringify(index.key);
      const unique = index.unique ? ' (UNIQUE)' : '';
      console.log(`- ${index.name}: ${keyStr}${unique}`);
    });

    console.log('\nðŸŽ¯ Index migration complete!');
    console.log('\nðŸ’¡ Performance benefits:');
    console.log('   â€¢ Prevents duplicate oven + hydraBatch combinations');
    console.log('   â€¢ 10-100x faster queries for process fetching');
    console.log('   â€¢ Eliminates race conditions in startOvenProcess');
    console.log('   â€¢ Optimized sorting and filtering operations');
  } catch (error) {
    console.error('ðŸ’¥ Migration failed:', error);
    process.exit(1);
  }
}

/**
 * Cleanup script to remove duplicate records before creating unique index
 * Run this first if you have existing duplicates
 */
async function cleanupDuplicates() {
  try {
    console.log('ðŸ§¹ Checking for duplicate oven + hydraBatch combinations...');

    const collection = await dbc('oven_processes');

    // Find duplicates using aggregation
    const duplicates = await collection
      .aggregate([
        {
          $group: {
            _id: { oven: '$oven', hydraBatch: '$hydraBatch' },
            count: { $sum: 1 },
            docs: { $push: '$_id' },
          },
        },
        {
          $match: { count: { $gt: 1 } },
        },
      ])
      .toArray();

    if (duplicates.length === 0) {
      console.log('âœ… No duplicates found - ready for unique index creation');
      return;
    }

    console.log(`âš ï¸  Found ${duplicates.length} duplicate groups:`);

    for (const duplicate of duplicates) {
      const { oven, hydraBatch } = duplicate._id;
      const docIds = duplicate.docs;
      console.log(
        `- Oven: ${oven}, Batch: ${hydraBatch} (${duplicate.count} documents)`,
      );

      // Keep the first document, remove the rest
      const idsToRemove = docIds.slice(1);
      if (idsToRemove.length > 0) {
        await collection.deleteMany({ _id: { $in: idsToRemove } });
        console.log(`  âœ… Removed ${idsToRemove.length} duplicate documents`);
      }
    }

    console.log('ðŸŽ¯ Duplicate cleanup complete!');
  } catch (error) {
    console.error('ðŸ’¥ Cleanup failed:', error);
    process.exit(1);
  }
}

// CLI interface
async function main() {
  const args = process.argv.slice(2);

  if (args.includes('--cleanup')) {
    await cleanupDuplicates();
    return;
  }

  if (args.includes('--help')) {
    console.log(`
ðŸ”§ Oven Processes Index Migration Script

Usage:
  bun run scripts/migrate-oven-indexes.ts              # Create indexes
  bun run scripts/migrate-oven-indexes.ts --cleanup    # Remove duplicates first
  bun run scripts/migrate-oven-indexes.ts --help       # Show this help

Indexes created:
  â€¢ oven_hydraBatch_unique: Prevents duplicate processes (UNIQUE)
  â€¢ oven_startTime_desc: Optimizes process listing queries
  â€¢ oven_status_startTime: Optimizes filtered queries
  â€¢ hydraBatch_status: Optimizes batch lookups
  â€¢ id_status: Optimizes process completion
    `);
    return;
  }

  await createOvenIndexes();
}

// Run if called directly
if (require.main === module) {
  main()
    .then(() => process.exit(0))
    .catch((error) => {
      console.error(error);
      process.exit(1);
    });
}

export { cleanupDuplicates, createOvenIndexes };
